{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = '/Users/JH/Desktop/NTU/NTU_Research/data/NEM_Load_Forecasting_Database.xls'\n",
    "\n",
    "concatenate_number = 2*4*4\n",
    "\n",
    "QLD = 'Actual_Data_QLD'\n",
    "NSW = 'Actual_Data_NSW'\n",
    "VIC = 'Actual_Data_VIC'\n",
    "SA = 'Actual_Data_SA'\n",
    "TAS = 'Actual_Data_TAS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Classes as Data Container\n",
    "\n",
    "class Structure:\n",
    "    def __init__(self):\n",
    "        self._feature = []\n",
    "        self._target = []\n",
    "\n",
    "    @property\n",
    "    def feature(self):\n",
    "        return self._feature\n",
    "\n",
    "    @property\n",
    "    def target(self):\n",
    "        return self._target\n",
    "\n",
    "    @feature.setter\n",
    "    def feature(self, value):\n",
    "        self._feature = value\n",
    "\n",
    "    @target.setter\n",
    "    def target(self, value):\n",
    "        self._target = value\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    class Train(Structure):\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "    class Test(Structure):\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    class Raw:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        class Train(Structure):\n",
    "            def __init__(self):\n",
    "                pass\n",
    "\n",
    "        class Test(Structure):\n",
    "            def __init__(self):\n",
    "                pass\n",
    "\n",
    "    class PreProcessed:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        class Train(Structure):\n",
    "            def __init__(self):\n",
    "                pass\n",
    "\n",
    "        class Test(Structure):\n",
    "            def __init__(self):\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Functions\n",
    "\n",
    "def normalization(data):\n",
    "    return (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "\n",
    "def data_splitter(data, ratio=0.8):\n",
    "    \"\"\"\n",
    "    split data into training data & testing data\n",
    "    :param data:\n",
    "\n",
    "    :param ratio:\n",
    "        training data ratio\n",
    "    :return:\n",
    "        train_data, test_data\n",
    "    \"\"\"\n",
    "    splitter = int(len(data) * ratio)\n",
    "    return np.array(data[:splitter]), np.array(data[splitter + 1:])\n",
    "\n",
    "\n",
    "def preprocessing_filter(data, nominator, denominator):\n",
    "    return normalization(data) ** (nominator / denominator)\n",
    "\n",
    "\n",
    "def preprocessing(data_present, temperature_max, temperature_mean, denominator):\n",
    "    data_present = list(data_present) + list(\n",
    "        preprocessing_filter(np.array(data_present), temperature_max, denominator)) + list(\n",
    "        preprocessing_filter(np.array(data_present), temperature_mean, denominator))\n",
    "\n",
    "    return np.array(data_present)\n",
    "\n",
    "\n",
    "def data_alloter(df):\n",
    "    dataset = DataSet()\n",
    "    denominator = df['Mean Tem.'].min()\n",
    "\n",
    "    raw_feature = []\n",
    "    raw_target = []\n",
    "    preprocessed_feature = []\n",
    "    preprocessed_target = []\n",
    "\n",
    "    for row in range(0, len(df)):\n",
    "        # if both MaxTemp and MeanTemp are not nan\n",
    "        if not math.isnan(df['Max Tem.'][row]) and not math.isnan(df['Mean Tem.'][row]):\n",
    "            if not math.isnan(df['Max Tem.'][row + 1]) and not math.isnan(df['Mean Tem.'][row + 1]):\n",
    "                powerload_present = normalization(np.array(df.loc[row][5:53]))\n",
    "                powerload_future = normalization(np.array(df.loc[row + 1][5:53]))\n",
    "\n",
    "                raw_feature.append(np.array(\n",
    "                    list(powerload_present) + list([df['Max Tem.'][row + 1]]) + list([df['Mean Tem.'][row + 1]])))\n",
    "                raw_target.append(np.array(powerload_future))\n",
    "\n",
    "                preprocessed_powerload_present = preprocessing(powerload_present,\n",
    "                                                               df['Max Tem.'][row + 1],\n",
    "                                                               df['Mean Tem.'][row + 1],\n",
    "                                                               denominator)\n",
    "\n",
    "                preprocessed_feature.append(preprocessed_powerload_present)\n",
    "                preprocessed_target.append(np.array(powerload_future))\n",
    "\n",
    "    dataset.Raw.Train.feature, dataset.Raw.Test.feature = data_splitter(raw_feature)\n",
    "    dataset.Raw.Train.target, dataset.Raw.Test.target = data_splitter(raw_target)\n",
    "\n",
    "    dataset.PreProcessed.Train.feature, dataset.PreProcessed.Test.feature = data_splitter(preprocessed_feature)\n",
    "    dataset.PreProcessed.Train.target, dataset.PreProcessed.Test.target = data_splitter(preprocessed_target)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(file, sheetname=QLD)\n",
    "dataset = data_alloter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MachineLearning Core(SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named scipy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-deda8c8086d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultioutput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiOutputClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named scipy"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
