{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA Multilayer Perceptron implementation example using TensorFlow library.\\nThis example is using the MNIST database of handwritten digits\\n(http://yann.lecun.com/exdb/mnist/)\\n\\nAuthor: Aymeric Damien\\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Parameters\n",
    "batch_size = 100\n",
    "num_steps = 4000\n",
    "data_showing_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "learning_rate_decayed = tf.placeholder(tf.float32, shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_decayed).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0100 cost= 3.612372159\n",
      "step: 0200 cost= 0.046545570\n",
      "step: 0300 cost= 0.036489483\n",
      "step: 0400 cost= 0.027970713\n",
      "step: 0500 cost= 0.018557151\n",
      "step: 0600 cost= 0.009317975\n",
      "step: 0700 cost= 0.018626598\n",
      "step: 0800 cost= 0.012463570\n",
      "step: 0900 cost= 0.007882543\n",
      "step: 1000 cost= 0.006299686\n",
      "step: 1100 cost= 0.008945249\n",
      "step: 1200 cost= 0.007009433\n",
      "step: 1300 cost= 0.008139231\n",
      "step: 1400 cost= 0.008677087\n",
      "step: 1500 cost= 0.001134169\n",
      "step: 1600 cost= 0.008046789\n",
      "step: 1700 cost= 0.010661273\n",
      "step: 1800 cost= 0.000055152\n",
      "step: 1900 cost= 0.005470282\n",
      "step: 2000 cost= 0.000717611\n",
      "step: 2100 cost= 0.014976241\n",
      "step: 2200 cost= 0.010334287\n",
      "step: 2300 cost= 0.001379655\n",
      "step: 2400 cost= 0.001192659\n",
      "step: 2500 cost= 0.010680760\n",
      "step: 2600 cost= 0.010929030\n",
      "step: 2700 cost= 0.005955373\n",
      "step: 2800 cost= 0.002402276\n",
      "step: 2900 cost= 0.001472202\n",
      "step: 3000 cost= 0.000511149\n",
      "step: 3100 cost= 0.000419174\n",
      "step: 3200 cost= 0.001526392\n",
      "step: 3300 cost= 0.013002790\n",
      "step: 3400 cost= 0.000887756\n",
      "step: 3500 cost= 0.000810381\n",
      "step: 3600 cost= 0.001035714\n",
      "step: 3700 cost= 0.009201771\n",
      "step: 3800 cost= 0.007457985\n",
      "step: 3900 cost= 0.002028300\n",
      "step: 4000 cost= 0.014321265\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    avg_cost = 0.\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    if 30000 < step < 80000:\n",
    "        learning_rate = 0.01 / 10\n",
    "    elif 80000 <= step < 200000:\n",
    "        learning_rate = 0.01 / 100\n",
    "    else:\n",
    "        learning_rate = 0.01\n",
    "\n",
    "    # set a offset\n",
    "    offset = (step * batch_size) % (mnist.train.labels.shape[0] - batch_size)\n",
    "\n",
    "    # Generate a minibatch.\n",
    "    batch_data = mnist.train.images[offset:(offset + batch_size), :]\n",
    "    batch_labels = mnist.train.labels[offset:(offset + batch_size), :]\n",
    "    \n",
    "    feed_dict = {x: batch_data, \n",
    "                 y: batch_labels,\n",
    "                 learning_rate_decayed: learning_rate}\n",
    "    \n",
    "    _, c = sess.run([optimizer, cost], feed_dict=feed_dict)\n",
    "    \n",
    "    # Compute average loss\n",
    "    avg_cost += c / total_batch\n",
    "    \n",
    "    if (step % data_showing_step == 0):\n",
    "        print \"step:\", '%04d' % (step+batch_size), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "print \"Optimization Finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9516\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n",
    "\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = sess.run(pred, feed_dict={x: mnist.test.images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-102.1829834 ,  -65.20870972,   26.33320808,   78.12233734,\n",
       "       -115.69210052,  -25.75245667, -353.78411865,  522.88085938,\n",
       "        -70.0782547 ,   89.16830444], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
