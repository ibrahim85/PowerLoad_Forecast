{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = '/Users/JH/Desktop/NTU/NTU_Research/data/NEM_Load_Forecasting_Database.xls'\n",
    "\n",
    "QLD = 'Actual_Data_QLD'\n",
    "NSW = 'Actual_Data_NSW'\n",
    "VIC = 'Actual_Data_VIC'\n",
    "SA = 'Actual_Data_SA'\n",
    "TAS = 'Actual_Data_TAS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Classes as Data Container\n",
    "\n",
    "class Structure:\n",
    "    def __init__(self):\n",
    "        self._feature = []\n",
    "        self._target = []\n",
    "\n",
    "    @property\n",
    "    def feature(self):\n",
    "        return self._feature\n",
    "\n",
    "    @property\n",
    "    def target(self):\n",
    "        return self._target\n",
    "\n",
    "    @feature.setter\n",
    "    def feature(self, value):\n",
    "        self._feature = value\n",
    "\n",
    "    @target.setter\n",
    "    def target(self, value):\n",
    "        self._target = value\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    class Train(Structure):\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "    class Test(Structure):\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    class Raw:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        class Train(Structure):\n",
    "            def __init__(self):\n",
    "                pass\n",
    "\n",
    "        class Test(Structure):\n",
    "            def __init__(self):\n",
    "                pass\n",
    "\n",
    "    class PreProcessed:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        class Train(Structure):\n",
    "            def __init__(self):\n",
    "                pass\n",
    "\n",
    "        class Test(Structure):\n",
    "            def __init__(self):\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Functions\n",
    "\n",
    "def normalization(data):\n",
    "    return (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "\n",
    "def data_splitter(data, ratio=0.8):\n",
    "    \"\"\"\n",
    "    split data into training data & testing data\n",
    "    :param data:\n",
    "\n",
    "    :param ratio:\n",
    "        training data ratio\n",
    "    :return:\n",
    "        train_data, test_data\n",
    "    \"\"\"\n",
    "    splitter = int(len(data) * ratio)\n",
    "    return np.array(data[:splitter]), np.array(data[splitter + 1:])\n",
    "\n",
    "\n",
    "def preprocessing_filter(data, nominator, denominator):\n",
    "    return normalization(data) ** (nominator / denominator)\n",
    "\n",
    "\n",
    "def preprocessing(data_present, temperature_max, temperature_mean, denominator):\n",
    "    data_present = list(data_present) + list(\n",
    "        preprocessing_filter(np.array(data_present), temperature_max, denominator)) + list(\n",
    "        preprocessing_filter(np.array(data_present), temperature_mean, denominator))\n",
    "\n",
    "    return np.array(data_present)\n",
    "\n",
    "\n",
    "def data_alloter(df):\n",
    "    dataset = DataSet()\n",
    "    denominator = df['Mean Tem.'].min()\n",
    "\n",
    "    raw_feature = []\n",
    "    raw_target = []\n",
    "    preprocessed_feature = []\n",
    "    preprocessed_target = []\n",
    "\n",
    "    for row in range(0, len(df)):\n",
    "        # if both MaxTemp and MeanTemp are not nan\n",
    "        if not math.isnan(df['Max Tem.'][row]) and not math.isnan(df['Mean Tem.'][row]):\n",
    "            if not math.isnan(df['Max Tem.'][row + 1]) and not math.isnan(df['Mean Tem.'][row + 1]):\n",
    "                powerload_present = normalization(np.array(df.loc[row][5:53]))\n",
    "                powerload_future = normalization(np.array(df.loc[row + 1][5:53]))\n",
    "\n",
    "                raw_feature.append(np.array(\n",
    "                    list(powerload_present) + list([df['Max Tem.'][row + 1]]) + list([df['Mean Tem.'][row + 1]])))\n",
    "                raw_target.append(np.array(powerload_future))\n",
    "\n",
    "                preprocessed_powerload_present = preprocessing(powerload_present,\n",
    "                                                               df['Max Tem.'][row + 1],\n",
    "                                                               df['Mean Tem.'][row + 1],\n",
    "                                                               denominator)\n",
    "\n",
    "                preprocessed_feature.append(preprocessed_powerload_present)\n",
    "                preprocessed_target.append(np.array(powerload_future))\n",
    "\n",
    "    dataset.Raw.Train.feature, dataset.Raw.Test.feature = data_splitter(raw_feature)\n",
    "    dataset.Raw.Train.target, dataset.Raw.Test.target = data_splitter(raw_target)\n",
    "\n",
    "    dataset.PreProcessed.Train.feature, dataset.PreProcessed.Test.feature = data_splitter(preprocessed_feature)\n",
    "    dataset.PreProcessed.Train.target, dataset.PreProcessed.Test.target = data_splitter(preprocessed_target)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(file, sheetname=QLD)\n",
    "dataset = data_alloter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 30\n",
    "num_steps = 5000\n",
    "data_showing_step = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 48\n",
    "n_steps = 3 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 48 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, n_steps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
